{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy import expand_dims\n",
    "from scipy.integrate import odeint,quad,dblquad,simps,quad_vec,nquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import datasets, layers, models\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Activation, concatenate\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from glob import glob \n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from colorspacious import cspace_converter\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pylab as py\n",
    "import threading\n",
    "import scipy\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy import constants\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from scipy.linalg import block_diag\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/alex/ml_master/virt/master_ml/cnn_fourier/data_cnn/label_10cm_5cm_focus_Siemensstar_10cm_1_METAL_L_Z96.50_.csv', '/home/alex/ml_master/virt/master_ml/cnn_fourier/data_cnn/label_10cm_5cm_focus_Siemensstar_10cm_1_METAL_V_Z96.50_.csv', '/home/alex/ml_master/virt/master_ml/cnn_fourier/data_cnn/label_10cm_5cm_focus_Siemensstar_10cm_1_phase_L_Z96.50_.csv', '/home/alex/ml_master/virt/master_ml/cnn_fourier/data_cnn/label_10cm_5cm_focus_Siemensstar_10cm_1p5_metal_V_Z96.50_.csv', '/home/alex/ml_master/virt/master_ml/cnn_fourier/data_cnn/label_10cm_5cm_focus_Siemensstar_10cm_2_phase_V_Z96.50_.csv']\n"
     ]
    }
   ],
   "source": [
    "# concatenate the CSV Files of the \n",
    "train_labels = sorted(glob('/home/alex/ml_master/virt/master_ml/cnn_fourier/data_cnn/label*.csv'))\n",
    "print(train_labels)\n",
    "# write header of csv file\n",
    "header = ['id','appliance']\n",
    "with open('data_cnn/header.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "\n",
    "# create dataset\n",
    "fout = open('data_cnn/train_labels.csv','a')\n",
    "\n",
    "for line in open('data_cnn/header.csv'):\n",
    "    fout.write(line)\n",
    "\n",
    "for i in range(5):\n",
    "    file = open(train_labels[i])\n",
    "#     file.__next__()\n",
    "    for line in file:\n",
    "        fout.write(line)\n",
    "    file.close()\n",
    "fout.close()\n",
    "# ######### weg got our dataset train_labels ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    appliance  \\\n",
      "id                                                              \n",
      "10cm_5cm_focus_Siemensstar_10cm_1_METAL_L_Z96.50            1   \n",
      "10cm_5cm_focus_Siemensstar_10cm_1_METAL_V_Z96.50            1   \n",
      "10cm_5cm_focus_Siemensstar_10cm_1_phase_L_Z96.50            1   \n",
      "10cm_5cm_focus_Siemensstar_10cm_1p5_metal_V_Z96.50          1   \n",
      "10cm_5cm_focus_Siemensstar_10cm_2_phase_V_Z96.50            1   \n",
      "\n",
      "                                                                                            amplitude  \\\n",
      "id                                                                                                      \n",
      "10cm_5cm_focus_Siemensstar_10cm_1_METAL_L_Z96.50    data_cnn/train/10cm_5cm_focus_Siemensstar_10cm...   \n",
      "10cm_5cm_focus_Siemensstar_10cm_1_METAL_V_Z96.50    data_cnn/train/10cm_5cm_focus_Siemensstar_10cm...   \n",
      "10cm_5cm_focus_Siemensstar_10cm_1_phase_L_Z96.50    data_cnn/train/10cm_5cm_focus_Siemensstar_10cm...   \n",
      "10cm_5cm_focus_Siemensstar_10cm_1p5_metal_V_Z96.50  data_cnn/train/10cm_5cm_focus_Siemensstar_10cm...   \n",
      "10cm_5cm_focus_Siemensstar_10cm_2_phase_V_Z96.50    data_cnn/train/10cm_5cm_focus_Siemensstar_10cm...   \n",
      "\n",
      "                                                                                                phase  \n",
      "id                                                                                                     \n",
      "10cm_5cm_focus_Siemensstar_10cm_1_METAL_L_Z96.50    data_cnn/train/10cm_5cm_focus_Siemensstar_10cm...  \n",
      "10cm_5cm_focus_Siemensstar_10cm_1_METAL_V_Z96.50    data_cnn/train/10cm_5cm_focus_Siemensstar_10cm...  \n",
      "10cm_5cm_focus_Siemensstar_10cm_1_phase_L_Z96.50    data_cnn/train/10cm_5cm_focus_Siemensstar_10cm...  \n",
      "10cm_5cm_focus_Siemensstar_10cm_1p5_metal_V_Z96.50  data_cnn/train/10cm_5cm_focus_Siemensstar_10cm...  \n",
      "10cm_5cm_focus_Siemensstar_10cm_2_phase_V_Z96.50    data_cnn/train/10cm_5cm_focus_Siemensstar_10cm...  \n"
     ]
    }
   ],
   "source": [
    "# Read the Dataset we created ####\n",
    "train_df = pd.read_csv('data_cnn/train_labels.csv', index_col=0)\n",
    "train_df['amplitude'] = train_df.index.map(lambda id: f'data_cnn/train/{id}_ampl.png')\n",
    "train_df['phase'] = train_df.index.map(lambda id: f'data_cnn/train/{id}_phase.png')\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_paths, img_rows, img_cols,  channels):\n",
    "    \"\"\"\n",
    "      Reads the spectogram files from disk and normalizes the pixel values\n",
    "        @params:\n",
    "          file_paths - Array of file paths to read from\n",
    "          img_rows - The image height.\n",
    "          img_cols - The image width.\n",
    "          as_grey - Read the image as Greyscale or RGB.\n",
    "          channels - Number of channels.\n",
    "        @returns:\n",
    "          The created and compiled model (Model)        \n",
    "    \"\"\"\n",
    "    images = []\n",
    "  \n",
    "    for file_path in file_paths:\n",
    "        images.append(imread(file_path, as_gray = False))\n",
    "    \n",
    "    images = np.asarray(images, dtype=np.float32)\n",
    "  \n",
    "  # normalize\n",
    "    images = images / 255.0 #np.max(images)\n",
    "  \n",
    "  # reshape to match Keras expectaions\n",
    "    images = images.reshape(images.shape[0], img_rows, img_cols, channels)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 120, 3)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Hyper Parameters ####\n",
    "\n",
    "## pixel if images ##\n",
    "img_rows, img_cols = 120, 120\n",
    "as_gray=True\n",
    "in_channels = 3 # rgb files\n",
    "num_classes = 0 # number of charts\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "input_shape = (img_rows, img_cols, in_channels)\n",
    "input_img = Input(shape= input_shape)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the images from CSV File ####\n",
    "\n",
    "x_train_amplitude=read_data(train_df.amplitude.values, img_rows, img_cols, in_channels)\n",
    "x_train_phase = read_data(train_df.phase.values, img_rows, img_cols, in_channels)\n",
    "\n",
    "# labels - convert class vectors to binary class matrices One Hot Encoding\n",
    "labels = train_df.appliance.values/2\n",
    "# labels = keras.utils.to_categorical(labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 120, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "# split the train data for test batches\n",
    "\n",
    "x_train_comp = np.stack((x_train_amplitude, x_train_phase), axis=4)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_comp, labels, test_size=0.2, random_state=666)\n",
    "\n",
    "# take them apart\n",
    "x_train_amplitude = x_train[:,:,:,:,0]\n",
    "x_test_amplitude = x_test[:,:,:,:,0]\n",
    "\n",
    "x_train_phase = x_train[:,:,:,:,1]\n",
    "x_test_phase = x_test[:,:,:,:,1]\n",
    "\n",
    "print(np.shape(x_test_phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x_train_amplitude, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolution_layers(input_img):\n",
    "    \n",
    "    model = Conv2D(32, (3, 3), padding='same', input_shape=input_shape)(input_img)\n",
    "    model = LeakyReLU(alpha=0.1)(model)\n",
    "    model = MaxPooling2D((2, 2),padding='same')(model)\n",
    "    model = Dropout(0.25)(model)\n",
    "  \n",
    "    model = Conv2D(64, (3, 3), padding='same')(model)\n",
    "    model = LeakyReLU(alpha=0.1)(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2),padding='same')(model)\n",
    "    model = Dropout(0.25)(model)\n",
    "    \n",
    "    model = Conv2D(128, (3, 3), padding='same')(model)\n",
    "    model = LeakyReLU(alpha=0.1)(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2),padding='same')(model)\n",
    "    model = Dropout(0.4)(model)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampl_input = Input(shape=input_shape)\n",
    "ampl_model = create_convolution_layers(ampl_input)\n",
    "\n",
    "phase_input = Input(shape=input_shape)\n",
    "phase_model = create_convolution_layers(phase_input)\n",
    "\n",
    "conv = concatenate([ampl_model, phase_model])\n",
    "\n",
    "conv = Flatten()(conv)\n",
    "\n",
    "dense = Dense(512)(conv)\n",
    "dense = LeakyReLU(alpha=0.1)(dense)\n",
    "dense = Dropout(0.5)(dense)\n",
    "\n",
    "output = Dense(num_classes, activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=[ampl_input, phase_input], outputs=output)\n",
    "\n",
    "opt = optimizers.Adam()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt)\n",
    "# model.summary()\n",
    "# np.shape(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-da305ab26372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test_amplitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_phase\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m          \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m          )\n",
      "\u001b[0;32m~/ml_master/virt/master_ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_master/virt/master_ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    990\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    991\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    993\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m                 \u001b[0;31m# Gets loss and metrics. Updates weights at each call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_master/virt/master_ml/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_master/virt/master_ml/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mp_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm_t\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mnew_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_master/virt/master_ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(x, new_x)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m     \"\"\"\n\u001b[0;32m--> 964\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_master/virt/master_ml/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         validate_shape=validate_shape)\n\u001b[0;32m--> 277\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "### Train the model###\n",
    "\n",
    "best_weights_file=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(best_weights_file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "\n",
    "model.fit([x_train_amplitude, x_train_phase], y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         callbacks=callbacks,\n",
    "         verbose=1,\n",
    "         validation_data=([x_test_amplitude, x_test_phase] ,y_test),\n",
    "         shuffle=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convolutional base \n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu', input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "\n",
    "## feed conv base into dense layer \n",
    "## flatten the base to 1D\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 2s 377ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt)\n",
    "\n",
    "history=model.fit(x_train, y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=100,\n",
    "         verbose=1,\n",
    "         validation_data=(X_test ,y_test),\n",
    "         shuffle=True\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
